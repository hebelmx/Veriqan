"""
End-to-end tests for the complete extraction pipeline.
"""

import pytest
from pathlib import Path
import json
import time
from unittest.mock import patch, Mock
import torch
from PIL import Image, ImageDraw, ImageFont

from src.api import PrismaExtractorAPI, quick_extract, compare_all_extractors
from src.factory import ExtractorFactory, create_extractor


class TestEndToEndAPI:
    """End-to-end tests using the high-level API."""
    
    @pytest.fixture
    def realistic_legal_document(self, temp_dir):
        \"\"\"Create a realistic legal document image.\"\"\"\n        # Create a more realistic document image\n        width, height = 1200, 1600\n        image = Image.new('RGB', (width, height), color='white')\n        draw = ImageDraw.Draw(image)\n        \n        # Try to use a font, fall back to default if not available\n        try:\n            font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf\", 24)\n            small_font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf\", 18)\n        except (OSError, IOError):\n            font = ImageFont.load_default()\n            small_font = ImageFont.load_default()\n        \n        # Document header\n        draw.rectangle([(50, 50), (width-50, 150)], fill='lightgray', outline='black')\n        draw.text((60, 80), \"COMISIÓN NACIONAL BANCARIA Y DE VALORES\", fill='black', font=font)\n        draw.text((60, 110), \"REQUERIMIENTO DE INFORMACIÓN\", fill='black', font=small_font)\n        \n        # Document body with key information\n        y_offset = 200\n        line_height = 40\n        \n        document_lines = [\n            \"FECHA: 15 de enero de 2024\",\n            \"EXPEDIENTE: CNBV/EXP/2024/001\",\n            \"AUTORIDAD EMISORA: Comisión Nacional Bancaria y de Valores\",\n            \"\",\n            \"TIPO DE REQUERIMIENTO: Solicitud de información bancaria\",\n            \"SUBTIPO: Movimientos de cuenta\",\n            \"\",\n            \"FUNDAMENTO LEGAL:\",\n            \"Artículo 142 de la Ley de Instituciones de Crédito\",\n            \"\",\n            \"PARTES INVOLUCRADAS:\",\n            \"- Banco Nacional de México S.A.\",\n            \"- Juan Pérez García\",\n            \"\",\n            \"DETALLE DEL REQUERIMIENTO:\",\n            \"Se requiere información sobre movimientos bancarios\",\n            \"del período enero-diciembre 2023 por un monto\",\n            \"total de $250,000.00 MXN\",\n        ]\n        \n        for line in document_lines:\n            if line.strip():  # Skip empty lines for drawing\n                draw.text((80, y_offset), line, fill='black', font=small_font)\n            y_offset += line_height\n        \n        # Save the image\n        image_path = temp_dir / \"realistic_legal_doc.png\"\n        image.save(image_path)\n        return image_path\n    \n    @pytest.mark.e2e\n    @pytest.mark.mock\n    def test_quick_extract_success(self, realistic_legal_document):\n        \"\"\"Test the quick_extract convenience function.\"\"\"\n        with patch('src.modules.model_loader.ModelLoader.load_model') as mock_load_model, \\\n             patch('src.modules.model_loader.ModelLoader.load_processor') as mock_load_processor, \\\n             patch('src.utils.device_utils.get_optimal_device_config') as mock_device_config:\n            \n            # Setup comprehensive mocks\n            mock_device_config.return_value = {\n                'device': 'cpu',\n                'dtype': torch.float32,\n                'attn_impl': None\n            }\n            \n            # Mock model and processor\n            mock_model = Mock()\n            mock_processor = Mock()\n            \n            # Mock the complete generation pipeline\n            generated_ids = torch.tensor([[1, 2, 3, 4, 5]])\n            mock_model.generate.return_value = generated_ids\n            \n            mock_processor.apply_chat_template.return_value = {\n                'input_ids': torch.tensor([[1, 2]]),\n                'attention_mask': torch.tensor([[1, 1]])\n            }\n            \n            # Return realistic JSON response\n            realistic_response = json.dumps({\n                \"fecha\": \"2024-01-15\",\n                \"autoridadEmisora\": \"Comisión Nacional Bancaria y de Valores\",\n                \"expediente\": \"CNBV/EXP/2024/001\",\n                \"tipoRequerimiento\": \"Solicitud de información bancaria\",\n                \"subtipoRequerimiento\": \"Movimientos de cuenta\",\n                \"partes\": [\"Banco Nacional de México S.A.\", \"Juan Pérez García\"],\n                \"detalle\": {\n                    \"descripcion\": \"Información sobre movimientos bancarios\",\n                    \"monto\": 250000.00,\n                    \"moneda\": \"MXN\"\n                }\n            }, ensure_ascii=False)\n            \n            mock_processor.batch_decode.return_value = [realistic_response]\n            \n            mock_load_model.return_value = mock_model\n            mock_load_processor.return_value = mock_processor\n            \n            # Perform quick extraction\n            result = quick_extract(realistic_legal_document, 'smolvlm')\n            \n            # Verify complete pipeline\n            assert isinstance(result, dict)\n            assert result['success'] is True\n            assert 'data' in result\n            assert 'processing_time' in result\n            \n            # Verify extracted data structure\n            data = result['data']\n            assert data['fecha'] == \"2024-01-15\"\n            assert data['autoridadEmisora'] == \"Comisión Nacional Bancaria y de Valores\"\n            assert data['expediente'] == \"CNBV/EXP/2024/001\"\n            assert isinstance(data['partes'], list)\n            assert len(data['partes']) == 2\n            assert isinstance(data['detalle'], dict)\n            assert data['detalle']['monto'] == 250000.00\n    \n    @pytest.mark.e2e\n    @pytest.mark.mock\n    def test_api_context_manager(self, realistic_legal_document):\n        \"\"\"Test the API context manager functionality.\"\"\"\n        with patch('src.modules.model_loader.ModelLoader.load_model') as mock_load_model, \\\n             patch('src.modules.model_loader.ModelLoader.load_processor') as mock_load_processor, \\\n             patch('src.utils.device_utils.get_optimal_device_config') as mock_device_config:\n            \n            # Setup mocks\n            mock_device_config.return_value = {'device': 'cpu', 'dtype': torch.float32}\n            \n            mock_model = Mock()\n            mock_processor = Mock()\n            generated_ids = torch.tensor([[1, 2, 3]])\n            mock_model.generate.return_value = generated_ids\n            \n            mock_processor.apply_chat_template.return_value = {\n                'input_ids': torch.tensor([[1]]), \n                'attention_mask': torch.tensor([[1]])\n            }\n            mock_processor.batch_decode.return_value = ['{\"fecha\": \"2024-01-15\", \"autoridadEmisora\": \"CNBV\"}']\n            \n            mock_load_model.return_value = mock_model\n            mock_load_processor.return_value = mock_processor\n            \n            # Test context manager\n            with PrismaExtractorAPI() as api:\n                # Perform extraction\n                result = api.extract(realistic_legal_document, 'smolvlm')\n                \n                assert isinstance(result, dict)\n                assert result['success'] is True\n                \n                # Get performance metrics\n                performance = api.get_performance_report()\n                assert isinstance(performance, dict)\n                assert 'api_level' in performance\n                \n                # Get error statistics\n                error_stats = api.get_error_statistics()\n                assert isinstance(error_stats, dict)\n                assert 'api_level' in error_stats\n    \n    @pytest.mark.e2e\n    @pytest.mark.mock\n    def test_batch_extraction(self, create_test_images, save_test_image):\n        \"\"\"Test batch extraction functionality.\"\"\"\n        with patch('src.modules.model_loader.ModelLoader.load_model') as mock_load_model, \\\n             patch('src.modules.model_loader.ModelLoader.load_processor') as mock_load_processor, \\\n             patch('src.utils.device_utils.get_optimal_device_config') as mock_device_config:\n            \n            # Setup mocks\n            mock_device_config.return_value = {'device': 'cpu', 'dtype': torch.float32}\n            \n            mock_model = Mock()\n            mock_processor = Mock()\n            generated_ids = torch.tensor([[1, 2, 3]])\n            mock_model.generate.return_value = generated_ids\n            \n            mock_processor.apply_chat_template.return_value = {\n                'input_ids': torch.tensor([[1]]), \n                'attention_mask': torch.tensor([[1]])\n            }\n            \n            # Return different responses for each image\n            mock_processor.batch_decode.side_effect = [\n                ['{\"fecha\": \"2024-01-15\", \"expediente\": \"EXP-001\"}'],\n                ['{\"fecha\": \"2024-01-16\", \"expediente\": \"EXP-002\"}'],\n                ['{\"fecha\": \"2024-01-17\", \"expediente\": \"EXP-003\"}']\n            ]\n            \n            mock_load_model.return_value = mock_model\n            mock_load_processor.return_value = mock_processor\n            \n            # Create test images\n            test_images = [\n                create_test_images(width=800, height=600, add_text_patterns=True),\n                create_test_images(width=1000, height=750, add_text_patterns=True),\n                create_test_images(width=1200, height=900, add_text_patterns=True)\n            ]\n            \n            image_paths = []\n            for i, img in enumerate(test_images):\n                path = save_test_image(img, f'batch_e2e_{i}.png')\n                image_paths.append(str(path))\n            \n            # Perform batch extraction\n            with PrismaExtractorAPI() as api:\n                results = api.extract_batch(image_paths, 'smolvlm')\n            \n            # Verify results\n            assert len(results) == 3\n            \n            for i, result in enumerate(results):\n                assert isinstance(result, dict)\n                assert result['success'] is True\n                assert 'data' in result\n                assert result['data']['expediente'] == f'EXP-00{i+1}'\n    \n    @pytest.mark.e2e\n    @pytest.mark.mock\n    def test_extractor_comparison(self, realistic_legal_document):\n        \"\"\"Test comparing multiple extractors.\"\"\"\n        # Mock all extractor types\n        with patch('src.modules.model_loader.ModelLoader.load_model') as mock_load_model, \\\n             patch('src.modules.model_loader.ModelLoader.load_processor') as mock_load_processor, \\\n             patch('src.utils.device_utils.get_optimal_device_config') as mock_device_config, \\\n             patch('paddleocr.PaddleOCR') as mock_paddle_class, \\\n             patch('doctr.models.ocr_predictor') as mock_doctr_predictor:\n            \n            # Setup SmolVLM mocks\n            mock_device_config.return_value = {'device': 'cpu', 'dtype': torch.float32}\n            mock_model = Mock()\n            mock_processor = Mock()\n            generated_ids = torch.tensor([[1, 2, 3]])\n            mock_model.generate.return_value = generated_ids\n            mock_processor.apply_chat_template.return_value = {'input_ids': torch.tensor([[1]]), 'attention_mask': torch.tensor([[1]])}\n            mock_processor.batch_decode.return_value = ['{\"fecha\": \"2024-01-15\", \"autoridadEmisora\": \"CNBV\", \"extractor\": \"smolvlm\"}']\n            mock_load_model.return_value = mock_model\n            mock_load_processor.return_value = mock_processor\n            \n            # Setup PaddleOCR mocks\n            mock_paddle = Mock()\n            mock_paddle.ocr.return_value = [\n                [[[10, 10], [100, 10], [100, 30], [10, 30]], ['FECHA: 2024-01-15', 0.95]],\n                [[[10, 50], [200, 50], [200, 70], [10, 70]], ['AUTORIDAD: CNBV', 0.92]]\n            ]\n            mock_paddle_class.return_value = mock_paddle\n            \n            # Setup DocTR mocks\n            mock_doctr = Mock()\n            mock_doctr_result = Mock()\n            mock_doctr_result.render.return_value = \"FECHA: 2024-01-15\\nAUTORIDAD: CNBV\"\n            mock_doctr.predict.return_value = mock_doctr_result\n            mock_doctr_predictor.return_value = mock_doctr\n            \n            # Compare all extractors\n            results = compare_all_extractors(realistic_legal_document)\n            \n            # Verify results for each extractor\n            assert isinstance(results, dict)\n            assert len(results) >= 3  # At least smolvlm, paddle, doctr\n            \n            for extractor_name, result in results.items():\n                assert isinstance(result, dict)\n                assert 'success' in result\n                assert 'processing_time' in result\n                \n                if result['success']:\n                    assert 'data' in result\n                    assert isinstance(result['data'], dict)\n    \n    @pytest.mark.e2e\n    def test_factory_pattern_e2e(self, realistic_legal_document, test_config):\n        \"\"\"Test end-to-end workflow using factory pattern.\"\"\"\n        with patch('src.modules.model_loader.ModelLoader.load_model') as mock_load_model, \\\n             patch('src.modules.model_loader.ModelLoader.load_processor') as mock_load_processor, \\\n             patch('src.utils.device_utils.get_optimal_device_config') as mock_device_config:\n            \n            # Setup mocks\n            mock_device_config.return_value = {'device': 'cpu', 'dtype': torch.float32}\n            mock_model = Mock()\n            mock_processor = Mock()\n            generated_ids = torch.tensor([[1, 2, 3]])\n            mock_model.generate.return_value = generated_ids\n            mock_processor.apply_chat_template.return_value = {'input_ids': torch.tensor([[1]]), 'attention_mask': torch.tensor([[1]])}\n            mock_processor.batch_decode.return_value = ['{\"fecha\": \"2024-01-15\", \"autoridadEmisora\": \"Factory Test\"}']\n            mock_load_model.return_value = mock_model\n            mock_load_processor.return_value = mock_processor\n            \n            # Create factory with custom configuration\n            factory = ExtractorFactory(test_config)\n            \n            # Create extractor\n            extractor = factory.create_extractor('smolvlm')\n            \n            # Perform extraction\n            result = extractor.extract(realistic_legal_document)\n            \n            # Verify result\n            assert result.success is True\n            assert result.document is not None\n            assert isinstance(result.document.structured_data, dict)\n            \n            # Get device info\n            device_info = extractor.device_info\n            assert isinstance(device_info, dict)\n            assert 'extractor' in device_info\n            \n            # Cleanup\n            extractor.cleanup()\n    \n    @pytest.mark.e2e\n    @pytest.mark.mock\n    def test_error_recovery_e2e(self, realistic_legal_document):\n        \"\"\"Test end-to-end error recovery scenarios.\"\"\"\n        with patch('src.modules.model_loader.ModelLoader.load_model') as mock_load_model, \\\n             patch('src.modules.model_loader.ModelLoader.load_processor') as mock_load_processor, \\\n             patch('src.utils.device_utils.get_optimal_device_config') as mock_device_config:\n            \n            # Setup mocks to fail initially, then succeed\n            mock_device_config.return_value = {'device': 'cpu', 'dtype': torch.float32}\n            mock_model = Mock()\n            mock_processor = Mock()\n            \n            # First call fails, subsequent calls succeed\n            call_count = {'count': 0}\n            def side_effect(*args, **kwargs):\n                call_count['count'] += 1\n                if call_count['count'] == 1:\n                    raise RuntimeError(\"Temporary failure\")\n                return torch.tensor([[1, 2, 3]])\n            \n            mock_model.generate.side_effect = side_effect\n            mock_processor.apply_chat_template.return_value = {'input_ids': torch.tensor([[1]]), 'attention_mask': torch.tensor([[1]])}\n            mock_processor.batch_decode.return_value = ['{\"fecha\": \"2024-01-15\", \"recovered\": true}']\n            mock_load_model.return_value = mock_model\n            mock_load_processor.return_value = mock_processor\n            \n            with PrismaExtractorAPI() as api:\n                # First extraction should fail\n                result1 = api.extract(realistic_legal_document, 'smolvlm')\n                assert result1['success'] is False\n                assert \"Temporary failure\" in result1['error']\n                \n                # Second extraction should succeed\n                result2 = api.extract(realistic_legal_document, 'smolvlm')\n                assert result2['success'] is True\n                assert result2['data']['recovered'] is True\n    \n    @pytest.mark.e2e\n    @pytest.mark.slow\n    def test_performance_monitoring_e2e(self, create_test_images, save_test_image):\n        \"\"\"Test end-to-end performance monitoring.\"\"\"\n        with patch('src.modules.model_loader.ModelLoader.load_model') as mock_load_model, \\\n             patch('src.modules.model_loader.ModelLoader.load_processor') as mock_load_processor, \\\n             patch('src.utils.device_utils.get_optimal_device_config') as mock_device_config:\n            \n            # Setup mocks with artificial delays\n            mock_device_config.return_value = {'device': 'cpu', 'dtype': torch.float32}\n            mock_model = Mock()\n            mock_processor = Mock()\n            \n            def slow_generate(*args, **kwargs):\n                time.sleep(0.1)  # Simulate processing time\n                return torch.tensor([[1, 2, 3]])\n            \n            mock_model.generate.side_effect = slow_generate\n            mock_processor.apply_chat_template.return_value = {'input_ids': torch.tensor([[1]]), 'attention_mask': torch.tensor([[1]])}\n            mock_processor.batch_decode.return_value = ['{\"fecha\": \"2024-01-15\"}']\n            mock_load_model.return_value = mock_model\n            mock_load_processor.return_value = mock_processor\n            \n            # Create test images\n            test_images = []\n            for i in range(5):\n                img = create_test_images(width=400, height=300)\n                path = save_test_image(img, f'perf_test_{i}.png')\n                test_images.append(str(path))\n            \n            with PrismaExtractorAPI() as api:\n                start_time = time.time()\n                \n                # Process multiple images\n                results = []\n                for img_path in test_images:\n                    result = api.extract(img_path, 'smolvlm')\n                    results.append(result)\n                \n                total_time = time.time() - start_time\n                \n                # Verify all extractions\n                assert len(results) == 5\n                successful_extractions = sum(1 for r in results if r['success'])\n                assert successful_extractions == 5\n                \n                # Get performance report\n                performance_report = api.get_performance_report()\n                \n                # Verify performance metrics\n                assert isinstance(performance_report, dict)\n                assert 'api_level' in performance_report\n                \n                if 'summary' in performance_report['api_level']:\n                    summary = performance_report['api_level']['summary']\n                    if 'total_operations' in summary and summary['total_operations'] > 0:\n                        assert summary['total_operations'] >= 5\n                        assert summary['total_time'] > 0\n                \n                # Verify individual extraction times\n                for result in results:\n                    assert 'processing_time' in result\n                    assert result['processing_time'] > 0\n\n\nclass TestEndToEndErrorScenarios:\n    \"\"\"Test various end-to-end error scenarios.\"\"\"\n    \n    @pytest.mark.e2e\n    def test_invalid_image_paths(self):\n        \"\"\"Test handling of invalid image paths.\"\"\"\n        invalid_paths = [\n            \"nonexistent.jpg\",\n            \"/invalid/path/image.png\",\n            \"\",\n            \"not_an_image.txt\"\n        ]\n        \n        with PrismaExtractorAPI() as api:\n            for invalid_path in invalid_paths:\n                result = api.extract(invalid_path, 'smolvlm')\n                \n                assert isinstance(result, dict)\n                assert result['success'] is False\n                assert 'error' in result\n    \n    @pytest.mark.e2e\n    @pytest.mark.mock\n    def test_mixed_success_failure_batch(self, create_test_images, save_test_image):\n        \"\"\"Test batch processing with mixed success and failure.\"\"\"\n        with patch('src.modules.model_loader.ModelLoader.load_model') as mock_load_model, \\\n             patch('src.modules.model_loader.ModelLoader.load_processor') as mock_load_processor, \\\n             patch('src.utils.device_utils.get_optimal_device_config') as mock_device_config:\n            \n            # Setup mocks\n            mock_device_config.return_value = {'device': 'cpu', 'dtype': torch.float32}\n            mock_model = Mock()\n            mock_processor = Mock()\n            generated_ids = torch.tensor([[1, 2, 3]])\n            mock_model.generate.return_value = generated_ids\n            mock_processor.apply_chat_template.return_value = {'input_ids': torch.tensor([[1]]), 'attention_mask': torch.tensor([[1]])}\n            mock_processor.batch_decode.return_value = ['{\"fecha\": \"2024-01-15\"}']\n            mock_load_model.return_value = mock_model\n            mock_load_processor.return_value = mock_processor\n            \n            # Mix of valid and invalid paths\n            valid_image = create_test_images(width=400, height=300)\n            valid_path = save_test_image(valid_image, 'valid.png')\n            \n            mixed_paths = [\n                str(valid_path),  # Valid\n                \"nonexistent1.jpg\",  # Invalid\n                str(valid_path),  # Valid\n                \"nonexistent2.png\",  # Invalid\n            ]\n            \n            with PrismaExtractorAPI() as api:\n                results = api.extract_batch(mixed_paths, 'smolvlm')\n            \n            assert len(results) == 4\n            \n            # Check results\n            assert results[0]['success'] is True   # Valid\n            assert results[1]['success'] is False  # Invalid\n            assert results[2]['success'] is True   # Valid\n            assert results[3]['success'] is False  # Invalid\n            \n            # Verify error messages for failed extractions\n            assert 'error' in results[1]\n            assert 'error' in results[3]\n    \n    @pytest.mark.e2e\n    def test_unsupported_extractor_type(self, realistic_legal_document):\n        \"\"\"Test handling of unsupported extractor types.\"\"\"\n        with PrismaExtractorAPI() as api:\n            result = api.extract(realistic_legal_document, 'unsupported_extractor')\n            \n            assert isinstance(result, dict)\n            assert result['success'] is False\n            assert 'error' in result\n            assert 'unknown' in result['error'].lower() or 'unsupported' in result['error'].lower()\n\n\nclass TestEndToEndConfigurationScenarios:\n    \"\"\"Test various configuration scenarios end-to-end.\"\"\"\n    \n    @pytest.mark.e2e\n    @pytest.mark.mock\n    def test_custom_configuration(self, realistic_legal_document):\n        \"\"\"Test end-to-end with custom configuration.\"\"\"\n        custom_config = {\n            'extractors': {\n                'smolvlm': {\n                    'model_id': 'custom-model',\n                    'max_new_tokens': 256,\n                    'temperature': 0.0\n                }\n            },\n            'processing': {\n                'timeout': 60,\n                'batch_size': 2\n            },\n            'validation': {\n                'required_fields': ['fecha', 'autoridadEmisora'],\n                'strict_mode': False\n            }\n        }\n        \n        with patch('src.modules.model_loader.ModelLoader.load_model') as mock_load_model, \\\n             patch('src.modules.model_loader.ModelLoader.load_processor') as mock_load_processor, \\\n             patch('src.utils.device_utils.get_optimal_device_config') as mock_device_config:\n            \n            # Setup mocks\n            mock_device_config.return_value = {'device': 'cpu', 'dtype': torch.float32}\n            mock_model = Mock()\n            mock_processor = Mock()\n            generated_ids = torch.tensor([[1, 2, 3]])\n            mock_model.generate.return_value = generated_ids\n            mock_processor.apply_chat_template.return_value = {'input_ids': torch.tensor([[1]]), 'attention_mask': torch.tensor([[1]])}\n            mock_processor.batch_decode.return_value = ['{\"fecha\": \"2024-01-15\", \"autoridadEmisora\": \"Custom Config Test\"}']\n            mock_load_model.return_value = mock_model\n            mock_load_processor.return_value = mock_processor\n            \n            # Test with custom configuration\n            with PrismaExtractorAPI(custom_config) as api:\n                result = api.extract(realistic_legal_document, 'smolvlm')\n                \n                assert result['success'] is True\n                assert result['data']['autoridadEmisora'] == \"Custom Config Test\"\n                \n                # Verify configuration was applied\n                # This would be verified by checking the actual extractor configuration\n                # but since we're mocking, we verify the result\n    \n    @pytest.mark.e2e\n    def test_configuration_validation(self):\n        \"\"\"Test configuration validation in end-to-end scenarios.\"\"\"\n        # Test with invalid configuration\n        invalid_config = {\n            'extractors': {\n                'smolvlm': {\n                    'max_new_tokens': -1,  # Invalid negative value\n                    'temperature': 2.0     # Invalid temperature > 1\n                }\n            }\n        }\n        \n        # Should handle invalid configuration gracefully\n        try:\n            with PrismaExtractorAPI(invalid_config) as api:\n                # Configuration errors might be caught during initialization\n                # or during actual extraction\n                pass\n        except Exception as e:\n            # Should provide meaningful error message\n            assert isinstance(e, (ValueError, TypeError, RuntimeError))\n\n\nclass TestEndToEndPerformance:\n    \"\"\"Performance-focused end-to-end tests.\"\"\"\n    \n    @pytest.mark.e2e\n    @pytest.mark.slow\n    @pytest.mark.mock\n    def test_concurrent_processing_simulation(self, create_test_images, save_test_image):\n        \"\"\"Simulate concurrent processing scenarios.\"\"\"\n        with patch('src.modules.model_loader.ModelLoader.load_model') as mock_load_model, \\\n             patch('src.modules.model_loader.ModelLoader.load_processor') as mock_load_processor, \\\n             patch('src.utils.device_utils.get_optimal_device_config') as mock_device_config:\n            \n            # Setup mocks with minimal delay\n            mock_device_config.return_value = {'device': 'cpu', 'dtype': torch.float32}\n            mock_model = Mock()\n            mock_processor = Mock()\n            generated_ids = torch.tensor([[1, 2, 3]])\n            mock_model.generate.return_value = generated_ids\n            mock_processor.apply_chat_template.return_value = {'input_ids': torch.tensor([[1]]), 'attention_mask': torch.tensor([[1]])}\n            mock_processor.batch_decode.return_value = ['{\"fecha\": \"2024-01-15\"}']\n            mock_load_model.return_value = mock_model\n            mock_load_processor.return_value = mock_processor\n            \n            # Create multiple test images\n            test_images = []\n            for i in range(10):\n                img = create_test_images(width=200 + i*10, height=150 + i*5)\n                path = save_test_image(img, f'concurrent_{i}.png')\n                test_images.append(str(path))\n            \n            # Simulate concurrent API instances\n            apis = []\n            results = []\n            \n            try:\n                # Create multiple API instances\n                for i in range(3):\n                    api = PrismaExtractorAPI()\n                    apis.append(api)\n                \n                # Process images across different API instances\n                for i, image_path in enumerate(test_images):\n                    api = apis[i % len(apis)]\n                    result = api.extract(image_path, 'smolvlm')\n                    results.append(result)\n                \n                # Verify all processed successfully\n                assert len(results) == 10\n                successful = sum(1 for r in results if r['success'])\n                assert successful == 10\n                \n            finally:\n                # Cleanup all APIs\n                for api in apis:\n                    try:\n                        api.cleanup()\n                    except:\n                        pass\n    \n    @pytest.mark.e2e\n    @pytest.mark.mock\n    def test_memory_usage_patterns(self, create_test_images, save_test_image):\n        \"\"\"Test memory usage patterns in end-to-end scenarios.\"\"\"\n        with patch('src.modules.model_loader.ModelLoader.load_model') as mock_load_model, \\\n             patch('src.modules.model_loader.ModelLoader.load_processor') as mock_load_processor, \\\n             patch('src.utils.device_utils.get_optimal_device_config') as mock_device_config:\n            \n            # Setup mocks\n            mock_device_config.return_value = {'device': 'cpu', 'dtype': torch.float32}\n            mock_model = Mock()\n            mock_processor = Mock()\n            generated_ids = torch.tensor([[1, 2, 3]])\n            mock_model.generate.return_value = generated_ids\n            mock_processor.apply_chat_template.return_value = {'input_ids': torch.tensor([[1]]), 'attention_mask': torch.tensor([[1]])}\n            mock_processor.batch_decode.return_value = ['{\"fecha\": \"2024-01-15\"}']\n            mock_load_model.return_value = mock_model\n            mock_load_processor.return_value = mock_processor\n            \n            # Process images and verify cleanup\n            with PrismaExtractorAPI() as api:\n                # Process several images\n                for i in range(5):\n                    img = create_test_images(width=800, height=600)\n                    path = save_test_image(img, f'memory_test_{i}.png')\n                    \n                    result = api.extract(str(path), 'smolvlm')\n                    assert result['success'] is True\n                \n                # Get performance report (should show memory usage)\n                performance = api.get_performance_report()\n                assert isinstance(performance, dict)\n            \n            # After context manager exit, resources should be cleaned up