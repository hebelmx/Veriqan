"""
Integration tests for modular extractors.
"""

import pytest
from unittest.mock import Mock, patch, MagicMock
from pathlib import Path
from PIL import Image
import torch

from src.extractors_v2 import (
    SmolVLMModularExtractor,
    PaddleModularExtractor,
    DocTRModularExtractor
)
from src.models import ExtractionResult


class TestSmolVLMModularExtractor:
    """Integration tests for SmolVLM modular extractor."""
    
    @pytest.mark.integration
    @pytest.mark.mock
    def test_initialization(self, test_config):
        \"\"\"Test extractor initialization with mocked components.\"\"\"\n        with patch('src.modules.model_loader.ModelLoader.load_model') as mock_load_model, \\\n             patch('src.modules.model_loader.ModelLoader.load_processor') as mock_load_processor, \\\n             patch('src.utils.device_utils.get_optimal_device_config') as mock_device_config:\n            \n            # Setup mocks\n            mock_device_config.return_value = {\n                'device': 'cpu',\n                'dtype': torch.float32,\n                'attn_impl': None\n            }\n            mock_load_model.return_value = Mock()\n            mock_load_processor.return_value = Mock()\n            \n            # Create extractor\n            extractor = SmolVLMModularExtractor(test_config)\n            \n            # Verify initialization\n            assert extractor.name == 'SmolVLMModularExtractor'\n            assert hasattr(extractor, 'model_loader')\n            assert hasattr(extractor, 'image_processor')\n            assert hasattr(extractor, 'text_extractor')\n            \n            # Verify model loading was called\n            mock_load_model.assert_called_once()\n            mock_load_processor.assert_called_once()\n    \n    @pytest.mark.integration\n    @pytest.mark.mock\n    def test_extract_success(self, sample_document_image, save_test_image, mock_smolvlm_components, test_config):\n        \"\"\"Test successful extraction.\"\"\"\n        with patch('src.modules.model_loader.ModelLoader.load_model') as mock_load_model, \\\n             patch('src.modules.model_loader.ModelLoader.load_processor') as mock_load_processor, \\\n             patch('src.utils.device_utils.get_optimal_device_config') as mock_device_config:\n            \n            # Setup mocks\n            mock_device_config.return_value = {\n                'device': 'cpu',\n                'dtype': torch.float32,\n                'attn_impl': None\n            }\n            \n            # Setup model and processor mocks\n            mock_model = mock_smolvlm_components['model']\n            mock_processor = mock_smolvlm_components['processor']\n            \n            # Mock generation output\n            generated_ids = torch.tensor([[1, 2, 3, 4]])  # Dummy token IDs\n            mock_model.generate.return_value = generated_ids\n            \n            mock_load_model.return_value = mock_model\n            mock_load_processor.return_value = mock_processor\n            \n            # Create extractor\n            extractor = SmolVLMModularExtractor(test_config)\n            \n            # Save test image\n            image_path = save_test_image(sample_document_image, 'test_smolvlm.png')\n            \n            # Extract\n            result = extractor.extract(image_path)\n            \n            # Verify result\n            assert isinstance(result, ExtractionResult)\n            assert result.success is True\n            assert result.extractor_name == 'SmolVLMModularExtractor'\n            assert result.processing_time > 0\n            \n            # Verify model was called\n            mock_model.generate.assert_called_once()\n            mock_processor.apply_chat_template.assert_called_once()\n            mock_processor.batch_decode.assert_called_once()\n    \n    @pytest.mark.integration\n    @pytest.mark.mock\n    def test_extract_invalid_image(self, test_config):\n        \"\"\"Test extraction with invalid image path.\"\"\"\n        with patch('src.modules.model_loader.ModelLoader.load_model'), \\\n             patch('src.modules.model_loader.ModelLoader.load_processor'), \\\n             patch('src.utils.device_utils.get_optimal_device_config'):\n            \n            extractor = SmolVLMModularExtractor(test_config)\n            \n            # Try to extract from non-existent image\n            result = extractor.extract('nonexistent.jpg')\n            \n            # Should fail gracefully\n            assert isinstance(result, ExtractionResult)\n            assert result.success is False\n            assert 'not found' in result.error_message.lower()\n    \n    @pytest.mark.integration\n    @pytest.mark.mock\n    def test_batch_extract(self, create_test_images, save_test_image, mock_smolvlm_components, test_config):\n        \"\"\"Test batch extraction.\"\"\"\n        with patch('src.modules.model_loader.ModelLoader.load_model') as mock_load_model, \\\n             patch('src.modules.model_loader.ModelLoader.load_processor') as mock_load_processor, \\\n             patch('src.utils.device_utils.get_optimal_device_config') as mock_device_config:\n            \n            # Setup mocks\n            mock_device_config.return_value = {'device': 'cpu', 'dtype': torch.float32}\n            mock_model = mock_smolvlm_components['model']\n            mock_processor = mock_smolvlm_components['processor']\n            \n            generated_ids = torch.tensor([[1, 2, 3]])\n            mock_model.generate.return_value = generated_ids\n            \n            mock_load_model.return_value = mock_model\n            mock_load_processor.return_value = mock_processor\n            \n            # Create extractor\n            extractor = SmolVLMModularExtractor(test_config)\n            \n            # Create test images\n            test_images = [\n                create_test_images(width=800, height=600),\n                create_test_images(width=1000, height=750),\n                create_test_images(add_text_patterns=True)\n            ]\n            \n            image_paths = []\n            for i, img in enumerate(test_images):\n                path = save_test_image(img, f'batch_{i}.png')\n                image_paths.append(str(path))\n            \n            # Batch extract\n            results = extractor.batch_extract(image_paths)\n            \n            # Verify results\n            assert len(results) == 3\n            for result in results:\n                assert isinstance(result, ExtractionResult)\n                assert result.success is True\n                assert result.extractor_name == 'SmolVLMModularExtractor'\n            \n            # Verify model was called for each image\n            assert mock_model.generate.call_count == 3\n    \n    @pytest.mark.integration\n    @pytest.mark.mock\n    def test_device_info(self, test_config):\n        \"\"\"Test device information retrieval.\"\"\"\n        with patch('src.modules.model_loader.ModelLoader.load_model'), \\\n             patch('src.modules.model_loader.ModelLoader.load_processor'), \\\n             patch('src.utils.device_utils.get_optimal_device_config') as mock_device_config:\n            \n            mock_device_config.return_value = {\n                'device': 'cuda',\n                'dtype': torch.float16,\n                'attn_impl': 'flash_attention_2'\n            }\n            \n            extractor = SmolVLMModularExtractor(test_config)\n            \n            device_info = extractor.device_info\n            \n            assert isinstance(device_info, dict)\n            assert 'extractor' in device_info\n            assert 'model_id' in device_info\n            assert 'device' in device_info\n            assert 'dtype' in device_info\n            assert device_info['extractor'] == 'SmolVLMModularExtractor'\n\n\nclass TestPaddleModularExtractor:\n    \"\"\"Integration tests for Paddle OCR modular extractor.\"\"\"\n    \n    @pytest.mark.integration\n    @pytest.mark.mock\n    def test_initialization(self, test_config):\n        \"\"\"Test PaddleOCR extractor initialization.\"\"\"\n        with patch('paddleocr.PaddleOCR') as mock_paddle_class:\n            mock_ocr = Mock()\n            mock_paddle_class.return_value = mock_ocr\n            \n            extractor = PaddleModularExtractor(test_config)\n            \n            assert extractor.name == 'PaddleModularExtractor'\n            assert hasattr(extractor, 'ocr_model')\n            \n            # Verify PaddleOCR was initialized with correct config\n            mock_paddle_class.assert_called_once_with(\n                use_angle_cls=False,  # From test_config\n                lang='es',\n                use_gpu=False,\n                show_log=False\n            )\n    \n    @pytest.mark.integration\n    @pytest.mark.mock\n    def test_extract_success(self, sample_document_image, save_test_image, mock_paddle_components, test_config):\n        \"\"\"Test successful OCR extraction.\"\"\"\n        with patch('paddleocr.PaddleOCR') as mock_paddle_class:\n            mock_ocr = mock_paddle_components['ocr_model']\n            mock_paddle_class.return_value = mock_ocr\n            \n            extractor = PaddleModularExtractor(test_config)\n            \n            # Save test image\n            image_path = save_test_image(sample_document_image, 'test_paddle.png')\n            \n            # Extract\n            result = extractor.extract(image_path)\n            \n            # Verify result\n            assert isinstance(result, ExtractionResult)\n            assert result.success is True\n            assert result.extractor_name == 'PaddleModularExtractor'\n            \n            # Verify OCR was called\n            mock_ocr.ocr.assert_called_once()\n    \n    @pytest.mark.integration\n    @pytest.mark.mock\n    def test_text_postprocessing(self, test_config):\n        \"\"\"Test text post-processing functionality.\"\"\"\n        with patch('paddleocr.PaddleOCR') as mock_paddle_class:\n            mock_ocr = Mock()\n            mock_paddle_class.return_value = mock_ocr\n            \n            extractor = PaddleModularExtractor(test_config)\n            \n            # Test post-processing\n            raw_text = \"NÃºm. EXP-001\\nFecha: 2024-01-15\\nAutoridad Emisora: CONDUSEF\"\n            processed = extractor._post_process_text(raw_text)\n            \n            # Should create JSON-like structure\n            assert '{' in processed and '}' in processed\n            assert 'numero' in processed.lower()\n            assert 'fecha' in processed.lower()\n            assert 'autoridad' in processed.lower()\n\n\nclass TestDocTRModularExtractor:\n    \"\"\"Integration tests for DocTR modular extractor.\"\"\"\n    \n    @pytest.mark.integration\n    @pytest.mark.mock\n    def test_initialization(self, test_config):\n        \"\"\"Test DocTR extractor initialization.\"\"\"\n        with patch('doctr.models.ocr_predictor') as mock_ocr_predictor:\n            mock_predictor = Mock()\n            mock_ocr_predictor.return_value = mock_predictor\n            \n            extractor = DocTRModularExtractor(test_config)\n            \n            assert extractor.name == 'DocTRModularExtractor'\n            assert hasattr(extractor, 'ocr_model')\n            \n            # Verify predictor was created with correct config\n            mock_ocr_predictor.assert_called_once_with(\n                det_arch='db_resnet50',  # From test_config\n                reco_arch='crnn_vgg16_bn',\n                pretrained=False  # From test_config\n            )\n    \n    @pytest.mark.integration\n    @pytest.mark.mock\n    def test_extract_success(self, sample_document_image, save_test_image, mock_doctr_components, test_config):\n        \"\"\"Test successful DocTR extraction.\"\"\"\n        with patch('doctr.models.ocr_predictor') as mock_ocr_predictor:\n            mock_predictor = mock_doctr_components['ocr_model']\n            mock_ocr_predictor.return_value = mock_predictor\n            \n            extractor = DocTRModularExtractor(test_config)\n            \n            # Save test image\n            image_path = save_test_image(sample_document_image, 'test_doctr.png')\n            \n            # Extract\n            result = extractor.extract(image_path)\n            \n            # Verify result\n            assert isinstance(result, ExtractionResult)\n            assert result.success is True\n            assert result.extractor_name == 'DocTRModularExtractor'\n            \n            # Verify predictor was called\n            mock_predictor.predict.assert_called_once()\n    \n    @pytest.mark.integration\n    @pytest.mark.mock\n    def test_text_postprocessing(self, test_config):\n        \"\"\"Test DocTR text post-processing.\"\"\"\n        with patch('doctr.models.ocr_predictor') as mock_ocr_predictor:\n            mock_predictor = Mock()\n            mock_ocr_predictor.return_value = mock_predictor\n            \n            extractor = DocTRModularExtractor(test_config)\n            \n            # Test post-processing\n            raw_text = \"FECHA: 2024-01-15\\nAUTORIDAD EMISORA: CONDUSEF\\nEXPEDIENTE: EXP-001\"\n            processed = extractor._post_process_text(raw_text)\n            \n            # Should create structured JSON\n            assert '{' in processed and '}' in processed\n            \n            # Try to parse as JSON\n            import json\n            try:\n                parsed = json.loads(processed)\n                assert isinstance(parsed, dict)\n                assert 'fecha' in parsed or 'autoridad' in processed.lower()\n            except json.JSONDecodeError:\n                # Fallback to original text is acceptable\n                assert processed == raw_text\n\n\nclass TestExtractorIntegration:\n    \"\"\"Test integration between different extractor components.\"\"\"\n    \n    @pytest.mark.integration\n    @pytest.mark.mock\n    def test_extractor_cleanup(self, test_config):\n        \"\"\"Test proper cleanup of extractor resources.\"\"\"\n        with patch('src.modules.model_loader.ModelLoader.load_model'), \\\n             patch('src.modules.model_loader.ModelLoader.load_processor'), \\\n             patch('src.utils.device_utils.get_optimal_device_config'):\n            \n            extractor = SmolVLMModularExtractor(test_config)\n            \n            # Get initial state\n            initial_cache = extractor.model_loader.get_cached_models()\n            \n            # Cleanup\n            extractor.cleanup()\n            \n            # Verify cleanup was called on modules\n            final_cache = extractor.model_loader.get_cached_models()\n            assert final_cache['cache_size'] == 0\n    \n    @pytest.mark.integration\n    @pytest.mark.mock\n    def test_performance_monitoring_integration(self, sample_image, save_test_image, test_config):\n        \"\"\"Test integration with performance monitoring.\"\"\"\n        with patch('src.modules.model_loader.ModelLoader.load_model'), \\\n             patch('src.modules.model_loader.ModelLoader.load_processor'), \\\n             patch('src.utils.device_utils.get_optimal_device_config'):\n            \n            extractor = SmolVLMModularExtractor(test_config)\n            \n            # Save test image\n            image_path = save_test_image(sample_image, 'perf_test.png')\n            \n            # Extract (will fail due to mocking, but should record performance)\n            try:\n                result = extractor.extract(image_path)\n            except Exception:\n                pass  # Expected due to mocking\n            \n            # Get performance report\n            report = extractor.get_performance_report()\n            \n            assert isinstance(report, dict)\n            # Should have some performance data\n            if 'summary' in report and report['summary']['total_operations'] > 0:\n                assert 'total_operations' in report['summary']\n    \n    @pytest.mark.integration\n    @pytest.mark.mock\n    def test_error_handling_integration(self, test_config):\n        \"\"\"Test integration with error handling.\"\"\"\n        with patch('src.modules.model_loader.ModelLoader.load_model'), \\\n             patch('src.modules.model_loader.ModelLoader.load_processor'), \\\n             patch('src.utils.device_utils.get_optimal_device_config'):\n            \n            extractor = SmolVLMModularExtractor(test_config)\n            \n            # Try to extract from invalid path\n            result = extractor.extract('invalid/path/image.jpg')\n            \n            # Should handle error gracefully\n            assert isinstance(result, ExtractionResult)\n            assert result.success is False\n            assert result.error_message is not None\n            \n            # Check error statistics\n            error_stats = extractor.get_error_stats()\n            assert isinstance(error_stats, dict)\n    \n    @pytest.mark.integration\n    def test_configuration_propagation(self, test_config):\n        \"\"\"Test that configuration is properly propagated to modules.\"\"\"\n        # Modify config for testing\n        test_config['extractors']['smolvlm']['max_new_tokens'] = 256\n        test_config['processing']['timeout'] = 45\n        \n        with patch('src.modules.model_loader.ModelLoader.load_model'), \\\n             patch('src.modules.model_loader.ModelLoader.load_processor'), \\\n             patch('src.utils.device_utils.get_optimal_device_config'):\n            \n            extractor = SmolVLMModularExtractor(test_config)\n            \n            # Verify configuration was applied\n            assert extractor.max_new_tokens == 256\n            \n            # Verify config manager has the values\n            timeout = extractor.config_manager.get('processing.timeout')\n            assert timeout == 45\n    \n    @pytest.mark.integration\n    @pytest.mark.mock\n    def test_module_interaction(self, create_test_images, save_test_image, test_config):\n        \"\"\"Test interaction between different modules.\"\"\"\n        with patch('src.modules.model_loader.ModelLoader.load_model') as mock_load_model, \\\n             patch('src.modules.model_loader.ModelLoader.load_processor') as mock_load_processor, \\\n             patch('src.utils.device_utils.get_optimal_device_config') as mock_device_config:\n            \n            # Setup mocks\n            mock_device_config.return_value = {'device': 'cpu', 'dtype': torch.float32}\n            \n            mock_model = Mock()\n            mock_processor = Mock()\n            \n            # Mock the complete pipeline\n            generated_ids = torch.tensor([[1, 2, 3]])\n            mock_model.generate.return_value = generated_ids\n            \n            mock_processor.apply_chat_template.return_value = {\n                'input_ids': torch.tensor([[1, 2]]),\n                'attention_mask': torch.tensor([[1, 1]])\n            }\n            mock_processor.batch_decode.return_value = ['{\"fecha\": \"2024-01-15\", \"autoridadEmisora\": \"CONDUSEF\"}']\n            \n            mock_load_model.return_value = mock_model\n            mock_load_processor.return_value = mock_processor\n            \n            extractor = SmolVLMModularExtractor(test_config)\n            \n            # Create and save test image\n            test_image = create_test_images(add_text_patterns=True)\n            image_path = save_test_image(test_image, 'module_interaction.png')\n            \n            # Extract\n            result = extractor.extract(image_path)\n            \n            # Verify successful extraction\n            assert isinstance(result, ExtractionResult)\n            assert result.success is True\n            \n            # Verify the pipeline worked\n            # Image processing: load_image was called implicitly\n            # Model loading: load_model and load_processor were called\n            mock_load_model.assert_called_once()\n            mock_load_processor.assert_called_once()\n            \n            # Text extraction: model.generate was called\n            mock_model.generate.assert_called_once()\n            \n            # JSON parsing: should have parsed the mock response\n            assert result.document is not None\n            assert isinstance(result.document.structured_data, dict)\n            \n            # Document validation: should have validated the data\n            if 'fecha' in result.document.structured_data:\n                assert result.document.structured_data['fecha'] == '2024-01-15'\n\n\nclass TestExtractorErrorScenarios:\n    \"\"\"Test various error scenarios in extractor integration.\"\"\"\n    \n    @pytest.mark.integration\n    @pytest.mark.mock\n    def test_model_loading_failure(self, test_config):\n        \"\"\"Test handling of model loading failures.\"\"\"\n        with patch('src.modules.model_loader.ModelLoader.load_model') as mock_load_model, \\\n             patch('src.modules.model_loader.ModelLoader.load_processor'), \\\n             patch('src.utils.device_utils.get_optimal_device_config'):\n            \n            # Make model loading fail\n            mock_load_model.side_effect = RuntimeError(\"Model loading failed\")\n            \n            # Should handle initialization error gracefully\n            with pytest.raises(RuntimeError, match=\"Model loading failed\"):\n                SmolVLMModularExtractor(test_config)\n    \n    @pytest.mark.integration\n    @pytest.mark.mock\n    def test_extraction_failure(self, sample_image, save_test_image, test_config):\n        \"\"\"Test handling of extraction failures.\"\"\"\n        with patch('src.modules.model_loader.ModelLoader.load_model') as mock_load_model, \\\n             patch('src.modules.model_loader.ModelLoader.load_processor') as mock_load_processor, \\\n             patch('src.utils.device_utils.get_optimal_device_config'):\n            \n            # Setup mocks\n            mock_model = Mock()\n            mock_processor = Mock()\n            \n            # Make extraction fail\n            mock_model.generate.side_effect = RuntimeError(\"GPU out of memory\")\n            \n            mock_load_model.return_value = mock_model\n            mock_load_processor.return_value = mock_processor\n            \n            extractor = SmolVLMModularExtractor(test_config)\n            \n            # Save test image\n            image_path = save_test_image(sample_image, 'error_test.png')\n            \n            # Extract should fail gracefully\n            result = extractor.extract(image_path)\n            \n            assert isinstance(result, ExtractionResult)\n            assert result.success is False\n            assert \"GPU out of memory\" in result.error_message\n    \n    @pytest.mark.integration\n    @pytest.mark.mock  \n    def test_json_parsing_failure(self, sample_image, save_test_image, test_config):\n        \"\"\"Test handling of JSON parsing failures.\"\"\"\n        with patch('src.modules.model_loader.ModelLoader.load_model') as mock_load_model, \\\n             patch('src.modules.model_loader.ModelLoader.load_processor') as mock_load_processor, \\\n             patch('src.utils.device_utils.get_optimal_device_config'):\n            \n            # Setup mocks\n            mock_model = Mock()\n            mock_processor = Mock()\n            \n            # Return invalid JSON\n            generated_ids = torch.tensor([[1, 2, 3]])\n            mock_model.generate.return_value = generated_ids\n            mock_processor.batch_decode.return_value = ['This is not JSON at all']\n            \n            mock_load_model.return_value = mock_model\n            mock_load_processor.return_value = mock_processor\n            \n            extractor = SmolVLMModularExtractor(test_config)\n            \n            # Save test image\n            image_path = save_test_image(sample_image, 'json_error_test.png')\n            \n            # Extract should handle JSON parsing error\n            result = extractor.extract(image_path)\n            \n            assert isinstance(result, ExtractionResult)\n            assert result.success is True  # Should still succeed with fallback\n            \n            # Should contain raw output in fallback\n            if result.document:\n                data = result.document.structured_data\n                assert 'raw_output' in data or 'parse_error' in data