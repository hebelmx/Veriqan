name: Test Suite

on:
  push:
    branches: [ main, develop, feature/* ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run nightly tests at 2 AM UTC
    - cron: '0 2 * * *'

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Code Quality Checks
  lint-and-format:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install black isort flake8 mypy bandit safety
          pip install -r requirements.txt
          pip install -r requirements-test.txt
      
      - name: Check code formatting with Black
        run: black --check --diff src/ tests/
      
      - name: Check import sorting with isort
        run: isort --check-only --diff src/ tests/
      
      - name: Lint with flake8
        run: |
          flake8 src/ tests/ --count --select=E9,F63,F7,F82 --show-source --statistics
          flake8 src/ tests/ --count --exit-zero --max-complexity=10 --max-line-length=88 --statistics
      
      - name: Type checking with mypy
        run: mypy src/ --ignore-missing-imports --strict-optional
      
      - name: Security check with bandit
        run: bandit -r src/ -ll
      
      - name: Check dependencies for vulnerabilities
        run: safety check

  # Unit Tests
  unit-tests:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11']
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
      
      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-${{ matrix.python-version }}-pip-${{ hashFiles('requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-${{ matrix.python-version }}-pip-
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1 libglib2.0-0
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-test.txt
      
      - name: Run unit tests
        run: |
          pytest tests/unit/ \
            --cov=src \
            --cov-report=xml \
            --cov-report=term-missing \
            --cov-fail-under=70 \
            -v \
            --tb=short \
            --maxfail=5 \
            -m "unit and not slow"
      
      - name: Upload coverage to Codecov
        if: matrix.python-version == '3.11'
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          flags: unit-tests
          name: codecov-unit-${{ matrix.python-version }}

  # Integration Tests
  integration-tests:
    runs-on: ubuntu-latest
    needs: unit-tests
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-integration-${{ hashFiles('requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-integration-
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-test.txt
      
      - name: Generate test fixtures
        run: |
          cd tests/data/fixtures
          python generate_test_fixtures.py
      
      - name: Run integration tests
        run: |
          pytest tests/integration/ \
            --cov=src \
            --cov-append \
            --cov-report=xml \
            --cov-report=term-missing \
            -v \
            --tb=short \
            --maxfail=3 \
            -m "integration and mock"
            # Only run mocked integration tests in CI
      
      - name: Upload integration coverage
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          flags: integration-tests
          name: codecov-integration

  # End-to-End Tests
  e2e-tests:
    runs-on: ubuntu-latest
    needs: integration-tests
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop')
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-e2e-${{ hashFiles('requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-e2e-
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-test.txt
      
      - name: Generate test fixtures
        run: |
          cd tests/data/fixtures
          python generate_test_fixtures.py
      
      - name: Run E2E tests
        run: |
          pytest tests/e2e/ \
            --cov=src \
            --cov-append \
            --cov-report=xml \
            --cov-report=term-missing \
            -v \
            --tb=short \
            --maxfail=2 \
            -m "e2e and mock"
            # Only run mocked E2E tests in CI
      
      - name: Upload E2E coverage
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          flags: e2e-tests
          name: codecov-e2e

  # Performance Tests (Nightly)
  performance-tests:
    runs-on: ubuntu-latest
    needs: unit-tests
    if: github.event_name == 'schedule' || (github.event_name == 'push' && contains(github.event.head_commit.message, '[perf]'))
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-test.txt
      
      - name: Generate test fixtures
        run: |
          cd tests/data/fixtures
          python generate_test_fixtures.py
      
      - name: Run performance tests
        run: |
          pytest tests/performance/ \
            --benchmark-json=benchmark.json \
            -v \
            --tb=short \
            -m "performance and not slow"
      
      - name: Store benchmark result
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: Python Performance Benchmarks
          tool: 'pytest'
          output-file-path: benchmark.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          comment-on-alert: true
          alert-threshold: '200%'
          fail-on-alert: true

  # Security Scanning
  security-scan:
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
      
      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v2
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'

  # Test Report Generation
  test-report:
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, e2e-tests]
    if: always()
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-test.txt
      
      - name: Generate comprehensive test report
        run: |
          pytest tests/ \
            --html=test-report.html \
            --self-contained-html \
            --junitxml=test-results.xml \
            --cov=src \
            --cov-report=html \
            --cov-report=term \
            -m "unit or (integration and mock) or (e2e and mock)" \
            --tb=short \
            || true  # Don't fail if some tests fail
      
      - name: Upload test report
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: test-report-${{ github.run_number }}
          path: |
            test-report.html
            test-results.xml
            htmlcov/
          retention-days: 30
      
      - name: Comment PR with test results
        if: github.event_name == 'pull_request'
        uses: dorny/test-reporter@v1
        with:
          name: Test Results
          path: test-results.xml
          reporter: java-junit
          fail-on-error: false

  # Docker Build Test (Optional)
  docker-build:
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Build Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: false
          tags: prisma-extractors:test
          cache-from: type=gha
          cache-to: type=gha,mode=max
      
      - name: Test Docker image
        run: |
          docker run --rm prisma-extractors:test python -c "
          import sys
          sys.path.append('/app/src')
          from api import PrismaExtractorAPI
          print('Docker image test passed')
          "

  # Notification
  notify:
    runs-on: ubuntu-latest
    needs: [lint-and-format, unit-tests, integration-tests, e2e-tests]
    if: always() && (failure() || cancelled()) && github.ref == 'refs/heads/main'
    
    steps:
      - name: Notify on failure
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          channel: '#ci-cd'
          text: |
            ðŸš¨ Test Suite Failed on Main Branch
            
            Workflow: ${{ github.workflow }}
            Commit: ${{ github.sha }}
            Author: ${{ github.actor }}
            
            Please check the failed jobs and fix issues.
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}